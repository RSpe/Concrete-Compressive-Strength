{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!curl https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/compressive/Concrete_Data.xls -O\n!curl https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/compressive/Concrete_Readme.txt -O",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  122k  100  122k    0     0   158k      0 --:--:-- --:--:-- --:--:--  160k\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  3808  100  3808    0     0   9242      0 --:--:-- --:--:-- --:--:--  9356\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!ls",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Concrete-Compressive-Strength.ipynb  Concrete_Readme.txt\r\nConcrete_Data.xls\t\t     README.md\r\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "!cat Concrete_Readme.txt",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Concrete Compressive Strength \r\r\n\r\r\n---------------------------------\r\r\n\r\r\nData Type: multivariate\r\r\n \r\r\nAbstract: Concrete is the most important material in civil engineering. The \r\r\nconcrete compressive strength is a highly nonlinear function of age and \r\r\ningredients. These ingredients include cement, blast furnace slag, fly ash, \r\r\nwater, superplasticizer, coarse aggregate, and fine aggregate.\r\r\n\r\r\n---------------------------------\r\r\n\r\r\nSources: \r\r\n\r\r\n  Original Owner and Donor\r\r\n  Prof. I-Cheng Yeh\r\r\n  Department of Information Management \r\r\n  Chung-Hua University, \r\r\n  Hsin Chu, Taiwan 30067, R.O.C.\r\r\n  e-mail:icyeh@chu.edu.tw\r\r\n  TEL:886-3-5186511\r\r\n\r\r\n  Date Donated: August 3, 2007\r\r\n \r\r\n---------------------------------\r\r\n\r\r\nData Characteristics:\r\r\n    \r\r\nThe actual concrete compressive strength (MPa) for a given mixture under a \r\r\nspecific age (days) was determined from laboratory. Data is in raw form (not scaled). \r\r\n\r\r\nSummary Statistics: \r\r\n\r\r\nNumber of instances (observations): 1030\r\r\nNumber of Attributes: 9\r\r\nAttribute breakdown: 8 quantitative input variables, and 1 quantitative output variable\r\r\nMissing Attribute Values: None\r\r\n\r\r\n---------------------------------\r\r\n\r\r\nVariable Information:\r\r\n\r\r\nGiven is the variable name, variable type, the measurement unit and a brief description. \r\r\nThe concrete compressive strength is the regression problem. The order of this listing \r\r\ncorresponds to the order of numerals along the rows of the database. \r\r\n\r\r\nName -- Data Type -- Measurement -- Description\r\r\n\r\r\nCement (component 1) -- quantitative -- kg in a m3 mixture -- Input Variable\r\r\nBlast Furnace Slag (component 2) -- quantitative -- kg in a m3 mixture -- Input Variable\r\r\nFly Ash (component 3) -- quantitative -- kg in a m3 mixture -- Input Variable\r\r\nWater (component 4) -- quantitative -- kg in a m3 mixture -- Input Variable\r\r\nSuperplasticizer (component 5) -- quantitative -- kg in a m3 mixture -- Input Variable\r\r\nCoarse Aggregate (component 6) -- quantitative -- kg in a m3 mixture -- Input Variable\r\r\nFine Aggregate (component 7) -- quantitative -- kg in a m3 mixture -- Input Variable\r\r\nAge -- quantitative -- Day (1~365) -- Input Variable\r\r\nConcrete compressive strength -- quantitative -- MPa -- Output Variable \r\r\n---------------------------------\r\r\n\r\r\nPast Usage: \r\r\n\r\r\nMain\r\r\n1. I-Cheng Yeh, \"Modeling of strength of high performance concrete using artificial \r\r\nneural networks,\" Cement and Concrete Research, Vol. 28, No. 12, pp. 1797-1808 (1998).\r\r\n\r\r\nOthers\r\r\n2. I-Cheng Yeh, \"Modeling Concrete Strength with Augment-Neuron Networks,\" J. of \r\r\nMaterials in Civil Engineering, ASCE, Vol. 10, No. 4, pp. 263-268 (1998).\r\r\n\r\r\n3. I-Cheng Yeh, \"Design of High Performance Concrete Mixture Using Neural Networks,\"  \r\r\nJ. of Computing in Civil Engineering, ASCE, Vol. 13, No. 1, pp. 36-42 (1999).\r\r\n\r\r\n4. I-Cheng Yeh, \"Prediction of Strength of Fly Ash and Slag Concrete By The Use of \r\r\nArtificial Neural Networks,\" Journal of the Chinese Institute of Civil and Hydraulic \r\r\nEngineering, Vol. 15, No. 4, pp. 659-663 (2003).\r\r\n\r\r\n5. I-Cheng Yeh, \"A mix Proportioning Methodology for Fly Ash and Slag Concrete Using \r\r\nArtificial Neural Networks,\" Chung Hua Journal of Science and Engineering, Vol. 1, No. \r\r\n1, pp. 77-84 (2003).\r\r\n\r\r\n6. Yeh, I-Cheng, \"Analysis of strength of concrete using design of experiments and \r\r\nneural networks,\": Journal of Materials in Civil Engineering, ASCE, Vol.18, No.4, \r\r\npp.597-604 ?2006?.\r\r\n\r\r\n---------------------------------\r\r\n\r\r\nAcknowledgements, Copyright Information, and Availability:\r\r\n\r\r\nNOTE: Reuse of this database is unlimited with retention of copyright notice for \r\r\nProf. I-Cheng Yeh and the following published paper:\r\r\n\r\r\nI-Cheng Yeh, \"Modeling of strength of high performance concrete using artificial \r\r\nneural networks,\" Cement and Concrete Research, Vol. 28, No. 12, pp. 1797-1808 (1998)\r\r\n\r\r\n\r\r\n\r\r\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Mean imputation isn't needed bcause there is no missing values\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df = pd.read_excel(\"Concrete_Data.xls\", names=[\"Cement\", \"Blast Furnace Slag\", \"Fly Ash\", \"Water\", \"Superplasticizer\", \"Coarse Aggregate\", \"Fine Aggregate\", \"Age\", \"Concrete compressive strength\"])",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.head()",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cement</th>\n      <th>Blast Furnace Slag</th>\n      <th>Fly Ash</th>\n      <th>Water</th>\n      <th>Superplasticizer</th>\n      <th>Coarse Aggregate</th>\n      <th>Fine Aggregate</th>\n      <th>Age</th>\n      <th>Concrete compressive strength</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>540.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>162.0</td>\n      <td>2.5</td>\n      <td>1040.0</td>\n      <td>676.0</td>\n      <td>28</td>\n      <td>79.986111</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>540.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>162.0</td>\n      <td>2.5</td>\n      <td>1055.0</td>\n      <td>676.0</td>\n      <td>28</td>\n      <td>61.887366</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>332.5</td>\n      <td>142.5</td>\n      <td>0.0</td>\n      <td>228.0</td>\n      <td>0.0</td>\n      <td>932.0</td>\n      <td>594.0</td>\n      <td>270</td>\n      <td>40.269535</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>332.5</td>\n      <td>142.5</td>\n      <td>0.0</td>\n      <td>228.0</td>\n      <td>0.0</td>\n      <td>932.0</td>\n      <td>594.0</td>\n      <td>365</td>\n      <td>41.052780</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>198.6</td>\n      <td>132.4</td>\n      <td>0.0</td>\n      <td>192.0</td>\n      <td>0.0</td>\n      <td>978.4</td>\n      <td>825.5</td>\n      <td>360</td>\n      <td>44.296075</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n0   540.0                 0.0      0.0  162.0               2.5   \n1   540.0                 0.0      0.0  162.0               2.5   \n2   332.5               142.5      0.0  228.0               0.0   \n3   332.5               142.5      0.0  228.0               0.0   \n4   198.6               132.4      0.0  192.0               0.0   \n\n   Coarse Aggregate  Fine Aggregate  Age  Concrete compressive strength  \n0            1040.0           676.0   28                      79.986111  \n1            1055.0           676.0   28                      61.887366  \n2             932.0           594.0  270                      40.269535  \n3             932.0           594.0  365                      41.052780  \n4             978.4           825.5  360                      44.296075  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.dtypes",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Making everything floats so there is no variation in the data that may mess with the model later\ndf[\"Age\"] = df[\"Age\"].astype(float)",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4566c5f23d8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Making everything floats so there is no variation in the data that may mess with the model later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Age\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Age\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.dtypes",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-5cc0934cc03c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Remove answer to not mess with feature selection and for test/train split later\nfrom sklearn.utils.multiclass import type_of_target\nx = df.drop(\"Concrete compressive strength\", axis = 1)\ny = df[\"Concrete compressive strength\"]",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-f52e6779107d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Remove answer to not mess with feature selection and for test/train split later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulticlass\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Concrete compressive strength\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Concrete compressive strength\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.preprocessing import KBinsDiscretizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.tree import DecisionTreeClassifier",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Binning to remove noisy data and squash outliers, done on all attributes\ndef binning(string):\n    split = [[v] for v in x[string]]\n    est.fit(split)\n    transformed = est.transform(split)\n    x[string] = transformed\n\nest = KBinsDiscretizer(n_bins = 5, encode = \"ordinal\", strategy = \"quantile\") #Splits data into 5 equal bins then computes their average\nnames = list(x)\nfor string in names:\n    binning(string)\n\nx_bin = x.copy()",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'x' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-c56c93778c1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKBinsDiscretizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_bins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ordinal\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"quantile\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Splits data into 5 equal bins then computes their average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mbinning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Used to check if feature selection is removing the insignificant and correlated data\nax, fig = plt.subplots(figsize = (16, 10))\ncorrelation_matrix = x_bin.corr()\nsns.heatmap(correlation_matrix, annot = True, cmap = \"OrRd\")\nplt.show()",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-9ea061a205fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Used to check if feature selection is removing the insignificant and correlated data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcorrelation_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_bin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrelation_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"OrRd\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Feature selection using kbest to find attributes of the concrete that are statistically significant when calculating its strength\ndef feature_sel(x):\n    enc = LabelEncoder()\n    strength = enc.fit_transform(y)\n    clf = DecisionTreeClassifier()\n    #Using 3-fold cross validation decision tree\n    rfecv = RFECV(estimator = clf, step = 1, cv = StratifiedKFold(3), scoring = \"accuracy\", min_features_to_select = 2)\n    rfecv.fit(x, strength)\n    \n    greatest = 1\n    count = 0\n    remove = \"\"\n    features = list(x.columns)\n    print(\"Optimal number of features: \", rfecv.n_features_) #We can see if each iteration causes the number of optimal features to change and if this corresponds to the number removed\n    \n    plt.figure()\n    plt.xlabel(\"Number of features selected\")\n    plt.ylabel(\"Cross validation score\")\n    plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n    plt.show()\n    \n    for i in range(0, len(features)):\n        if rfecv.ranking_[i] > 1:\n            count += 1\n        if rfecv.ranking_[i] > greatest:\n            greatest == rfecv.ranking_[i]\n            remove = \"\"\n            remove += features[i]\n    if remove != \"\":\n        finish = x.drop(remove, axis = 1)\n        remove = \"\"\n        return finish, count\n    else:\n        return x, 0\n    \nx_binFeature, check = feature_sel(x_bin)\ncount = 0\nwhile check > 0: #This removes the least significant attribute then runs the feature selection again to see if there is still a reason to remove a data point (still insignificant)\n    x_binFeature, check = feature_sel(x_binFeature) \n    count += 1\n    \nprint(\"Features beforehand:\", 8, \", features removed :\", count, \", end optimal number of features : \", 8 - count) #If final optimal features = 6 then we expect 10 - 6 to be removed EXAMPLE",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'x_bin' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-838c43e5c82d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mx_binFeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_sel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_bin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#This removes the least significant attribute then runs the feature selection again to see if there is still a reason to remove a data point (still insignificant)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_bin' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Train on 70% of the data and test on 30%\ntrain_x, test_x, train_y, test_y = train_test_split(x_binFeature, y, test_size = 0.3)",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'x_binFeature' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-223a56835db7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Train on 70% of the data and test on 30%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_binFeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x_binFeature' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.linear_model import SGDRegressor",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Using a Linear model with Stochastic Gradient Descent to minimise chance that model gets stuck in local minima \nmodel = SGDRegressor()\n\nmodel.fit(train_x, train_y)",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_x' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-8a57bbe342eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGDRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_x' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "model.coef_\n\npredicted = model.predict(test_x)\nplt.plot(test_y, predicted) #Visualisation of model prediction accuracy",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'SGDRegressor' object has no attribute 'coef_'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-76f66872872c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Visualisation of model prediction accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'SGDRegressor' object has no attribute 'coef_'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "model.score(test_x, test_y)",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'test_x' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-59822c818022>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'test_x' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Compared to auto-mpg which I got an accuracy of 0.9959822026464998, this model is more inconsistent and less precise",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}